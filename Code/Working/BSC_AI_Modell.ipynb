{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Input\n",
    "from keras.losses import CategoricalCrossentropy \n",
    "import sys\n",
    "\n",
    "def column_one_hot (dataframe, columns): \n",
    "    for column in columns:\n",
    "        if column in dataframe:\n",
    "            one_hot = pd.get_dummies(dataframe[column])\n",
    "            dataframe = dataframe.drop(column,axis = 1)\n",
    "            dataframe = pd.concat([dataframe, one_hot], axis=1)\n",
    "    return dataframe\n",
    "\n",
    "def drop_columns (dataframe, columns):\n",
    "    for column in columns:\n",
    "        if column in dataframe.columns:\n",
    "            dataframe = dataframe.drop(column, axis=1)\n",
    "    return dataframe\n",
    "\n",
    "def drop_column (dataframe, column):\n",
    "    if column in dataframe.columns:\n",
    "        dataframe = dataframe.drop(column, axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SAR_Data.csv')\n",
    "df.shape\n",
    "\n",
    "status = df['Status'].unique()\n",
    "for x in status:\n",
    "    print(x + \" \" + str(len(df[df['Status'] == x])))\n",
    "\n",
    "print (\"----------------------------------------------------------------\")\n",
    "\n",
    "maskOpen = ((df['Status'] == 'postponed') | (df['Status'] == 'partly open') |( df['Status'] == 'In creation'))\n",
    "maskClosed = (df['Status'] == 'partly closed')\n",
    "df.loc[maskOpen, 'Status'] = 'open'\n",
    "df.loc[maskClosed, 'Status'] = 'closed'\n",
    "df.loc[(df['Status'] == 'non applicable'), 'Status'] = 'not applicable'\n",
    "status = df['Status'].unique()\n",
    "for x in status:\n",
    "    print(x + \" \" + str(len(df[df['Status'] == x])))\n",
    "\n",
    "# postponed, partly open, in creation -> open;    partly closed -> closed\n",
    "\n",
    "# falsche Ordnerstruktur in /RA Application Conditions/03_PG_OCS/Service and diagnostic systems\n",
    "# fehlt ein Ordner bevor Module kommen, deshalb händisch eintragen\n",
    "\n",
    "df.loc[df['Version'].str.contains('VICOS_S_D'), 'Product'] = 'VICOS_S_D'\n",
    "df.loc[df['Version'].str.contains('VICOS_S_D'), 'Version'] = df['Version'].str[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = df['Path'].unique()\n",
    "accessDB = pd.read_xml(\"X:/File/DE/bwga024a_IMORA_RM/05_Process_Management/14_Metriken & KPI/KPI-Erhebung/KPI_01-04_General/Data/Input/Input_BWG_Combined_Access.xml\")\n",
    "\n",
    "for path in paths:\n",
    "    try:\n",
    "        if(path == \"/ML Realization Projects Algeria\"):\n",
    "            result = accessDB.loc[(accessDB['Type'] == \"Real\") & (accessDB['Location'] == \"BWG\") & (accessDB['Offset'] == \"/ML Realization Projects Algeria/20006_ML_BM_Boughezoul_MSila\")].iloc[0]\n",
    "        else:\n",
    "            result = accessDB.loc[(accessDB['Type'] == \"Real\") & (accessDB['Location'] == \"BWG\") & ((accessDB['Offset'] == str(path)) | (accessDB['Offset'] == (str(path) + \"/\")))].iloc[0]           \n",
    "    except:\n",
    "        print(str(path) + \" has no entry in the AccessDB!\")\n",
    "\n",
    "    mask = df['Path'] == str(path)\n",
    "    df.loc[mask, 'Project_category'] = result['Project_category']\n",
    "    df.loc[mask, 'BS'] = result['BS']\n",
    "    df.loc[mask, 'RU'] = result['RU']\n",
    "    df.loc[mask, 'ProjectYear'] = result['ProjectYear']\n",
    "    df.loc[mask, 'section'] = result['section']\n",
    "    df.loc[mask, 'Project_name'] = result['Project_name']\n",
    "    df['ProductVersion'] = df[\"Product\"].str.cat(df[\"Version\"], sep = \"-\")\n",
    "\n",
    "df['ProjectYear'] = df['ProjectYear'].astype('int')\n",
    "df = df[['Text', 'Product', 'ProductVersion', 'Project_name', 'section', 'Project_category', 'BS', 'RU', 'ProjectYear', 'Status', 'Statement']]\n",
    "#df = drop_column(df, 'Statement') # später wieder löschen!\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST (WORKING!) ---------------------------------------\n",
    "products = df['Product'].unique()\n",
    "df = column_one_hot(df, ['Product'])\n",
    "projects = df['Project_name'].unique()\n",
    "for project in projects:\n",
    "    for product in products:\n",
    "        df.loc[df['Project_name'] == project, product] = 1 if (df.loc[df['Project_name'] == project][product].sum()) >= 1 else 0\n",
    "df = column_one_hot(df, ['ProductVersion', 'Project_name', 'section',\n",
    "       'Project_category', 'BS', 'RU', 'ProjectYear'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df\n",
    "text = \"Zur Anschaltung des Antriebes in der Außenanlage müssen Signalkabel nach VDE 0816/2 oder Kabel mit vergleichbaren Eigenschaften verwendet werden. Die Verlegevorschriften des Kabels sind einzuhalten.\"\n",
    "df_training = df_training.loc[df_training['Text'] == text]\n",
    "df_training.reset_index(inplace=True, drop=True)\n",
    "\n",
    "test_col = 12\n",
    "test = drop_columns(df_training.iloc[[test_col]], ['Text', 'Status', 'Statement'])\n",
    "df_training = df_training.drop(test_col)\n",
    "\n",
    "trainX = drop_columns(df_training, ['Status', 'Text', 'Statement'])\n",
    "trainYStatus = drop_column(column_one_hot(df_training[['Text', 'Status']], ['Status']), \"Text\")\n",
    "trainYStatement = drop_column(column_one_hot(df_training[['Text', 'Statement']], ['Statement']), \"Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelStatus = Sequential()\n",
    "modelStatus.add(Input(shape=trainX.shape[1]))\n",
    "modelStatus.add(Dense(16, activation='relu'))\n",
    "modelStatus.add(Dense(trainYStatus.shape[1], activation='softmax'))\n",
    "modelStatus.summary()\n",
    "modelStatus.compile(optimizer='adam',\n",
    "              loss=CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historyStatus = modelStatus.fit(trainX, trainYStatus,\n",
    "                    batch_size=2,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    validation_split=0.4)\n",
    "\n",
    "modelStatement = Sequential()\n",
    "modelStatement.add(Input(shape=trainX.shape[1]))\n",
    "modelStatement.add(Dense(16, activation='relu'))\n",
    "modelStatement.add(Dense(trainYStatement.shape[1], activation='softmax'))\n",
    "modelStatement.summary()\n",
    "modelStatement.compile(optimizer='adam',\n",
    "              loss=CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historyStatement = modelStatement.fit(trainX, trainYStatement,\n",
    "                    batch_size=2,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    validation_split=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionStatus = modelStatus.predict(test)\n",
    "col = 0\n",
    "for i in predictionStatus:\n",
    "    for j in i:\n",
    "        print (trainYStatus.columns[col] + \" \" + '{:.1%}'.format(j))\n",
    "        col += 1\n",
    "\n",
    "print (\"-----------------------------------------------------\")\n",
    "\n",
    "predictionStatement = modelStatement.predict(test)\n",
    "index_max = np.argmax(predictionStatement)\n",
    "print (trainYStatement.columns[index_max] + \" \" + '{:.1%}'.format(predictionStatement[0][index_max]))\n",
    "#col = 0\n",
    "#for i in predictionStatement:\n",
    "#    for j in i:\n",
    "#        print (trainYStatement.columns[col] + \" \" + '{:.1%}'.format(j))\n",
    "#        col += 1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur noch Infos --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = df['Status'].unique()\n",
    "hauefigkeit = []\n",
    "for x in status:\n",
    "    hauefigkeit.append(len(df[df['Status'] == x]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(hauefigkeit, labels=status, autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Product'].unique())\n",
    "df[df['Product'] == \"/\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i], y[i], ha = 'center')\n",
    "\n",
    "text = df['Text'].value_counts()\n",
    "eins = 0\n",
    "zwei = 0\n",
    "drei = 0\n",
    "vier = 0\n",
    "for anzahl in text:\n",
    "    if anzahl  < 5:                         # anzahl 0:4\n",
    "        eins += 1\n",
    "    if ((anzahl  >= 5) & (anzahl <= 9)):           # anzahl 5:9\n",
    "        zwei += 1                           \n",
    "    if ((anzahl  >= 10) & (anzahl <= 14)):           # anzahl 10:14\n",
    "        drei += 1\n",
    "    if anzahl  >= 15:                       # anzahl ab 15\n",
    "        vier += 1\n",
    "y = [eins, zwei, drei, vier]\n",
    "x = ('0-4', '5-9', '10-14', 'ab 15')\n",
    "\n",
    "\n",
    "plt.bar(x, y, align='center')\n",
    "plt.xticks(x)\n",
    "plt.title('Anzahl Anwendungsregeln nach Häufigkeit der Bewertung')\n",
    "addlabels(x, y)\n",
    "plt.show()\n",
    "\n",
    "print (\"Anzahl Anwendungsregeln, welche nur einmal bewertet wurden: \" + str(eins))\n",
    "print (\"Anteil am Datensatz: \" + str(round(round(eins/df.shape[0], 4) * 100, 2)) + \"%\")\n",
    "    \n",
    "#text.head(10)\n",
    "#test = df.loc[df['Text'] == \"Zur Anschaltung des Antriebes in der Außenanlage müssen Signalkabel nach VDE 0816/2 oder Kabel mit vergleichbaren Eigenschaften verwendet werden. Die Verlegevorschriften des Kabels sind einzuhalten.\"]\n",
    "#test.reset_index(inplace=True, drop=True)\n",
    "#test.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historyStatus.history['loss'], label = 'Training loss')\n",
    "plt.plot(historyStatus.history['val_loss'], label = 'Validation loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
