{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.losses import CategoricalCrossentropy \n",
    "import sys\n",
    "\n",
    "def column_one_hot (dataframe, columns): \n",
    "    for column in columns:\n",
    "        if column in dataframe:\n",
    "            one_hot = pd.get_dummies(dataframe[column])\n",
    "            dataframe = dataframe.drop(column,axis = 1)\n",
    "            dataframe = pd.concat([dataframe, one_hot], axis=1)\n",
    "    return dataframe\n",
    "\n",
    "def drop_columns (dataframe, columns):\n",
    "    for column in columns:\n",
    "        if column in dataframe.columns:\n",
    "            dataframe = dataframe.drop(column, axis=1)\n",
    "    return dataframe\n",
    "\n",
    "def drop_column (dataframe, column):\n",
    "    if column in dataframe.columns:\n",
    "        dataframe = dataframe.drop(column, axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SAR_Data.csv')\n",
    "df.shape\n",
    "\n",
    "status = df['Status'].unique()\n",
    "\n",
    "maskOpen = ((df['Status'] == 'postponed') | (df['Status'] == 'partly open') |( df['Status'] == 'In creation'))\n",
    "maskClosed = (df['Status'] == 'partly closed')\n",
    "df.loc[maskOpen, 'Status'] = 'open'\n",
    "df.loc[maskClosed, 'Status'] = 'closed'\n",
    "df.loc[(df['Status'] == 'non applicable'), 'Status'] = 'not applicable'\n",
    "status = df['Status'].unique()\n",
    "\n",
    "# postponed, partly open, in creation -> open;    partly closed -> closed\n",
    "\n",
    "# falsche Ordnerstruktur in /RA Application Conditions/03_PG_OCS/Service and diagnostic systems\n",
    "# fehlt ein Ordner bevor Module kommen, deshalb händisch eintragen\n",
    "\n",
    "df.loc[df['Version'].str.contains('VICOS_S_D'), 'Product'] = 'VICOS_S_D'\n",
    "df.loc[df['Version'].str.contains('VICOS_S_D'), 'Version'] = df['Version'].str[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14572, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = df['Path'].unique()\n",
    "accessDB = pd.read_xml(\"X:/File/DE/bwga024a_IMORA_RM/05_Process_Management/14_Metriken & KPI/KPI-Erhebung/KPI_01-04_General/Data/Input/Input_BWG_Combined_Access.xml\")\n",
    "\n",
    "for path in paths:\n",
    "    try:\n",
    "        if(path == \"/ML Realization Projects Algeria\"):\n",
    "            result = accessDB.loc[(accessDB['Type'] == \"Real\") & (accessDB['Location'] == \"BWG\") & (accessDB['Offset'] == \"/ML Realization Projects Algeria/20006_ML_BM_Boughezoul_MSila\")].iloc[0]\n",
    "        else:\n",
    "            result = accessDB.loc[(accessDB['Type'] == \"Real\") & (accessDB['Location'] == \"BWG\") & ((accessDB['Offset'] == str(path)) | (accessDB['Offset'] == (str(path) + \"/\")))].iloc[0]           \n",
    "    except:\n",
    "        print(str(path) + \" has no entry in the AccessDB!\")\n",
    "\n",
    "    mask = df['Path'] == str(path)\n",
    "    df.loc[mask, 'Project_category'] = result['Project_category']\n",
    "    df.loc[mask, 'BS'] = result['BS']\n",
    "    df.loc[mask, 'RU'] = result['RU']\n",
    "    df.loc[mask, 'ProjectYear'] = result['ProjectYear']\n",
    "    df.loc[mask, 'section'] = result['section']\n",
    "    df.loc[mask, 'Project_name'] = result['Project_name']\n",
    "    df['ProductVersion'] = df[\"Product\"].str.cat(df[\"Version\"], sep = \"-\")\n",
    "\n",
    "df['ProjectYear'] = df['ProjectYear'].astype('int')\n",
    "df = df[['Text', 'Product', 'ProductVersion', 'Project_name', 'section', 'Project_category', 'BS', 'RU', 'ProjectYear', 'Status', 'Statement']]\n",
    "#df = drop_column(df, 'Statement') # später wieder löschen!\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14572, 180)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST (WORKING!) ---------------------------------------\n",
    "products = df['Product'].unique()\n",
    "df = column_one_hot(df, ['Product'])\n",
    "projects = df['Project_name'].unique()\n",
    "for project in projects:\n",
    "    for product in products:\n",
    "        df.loc[df['Project_name'] == project, product] = 1 if (df.loc[df['Project_name'] == project][product].sum()) >= 1 else 0\n",
    "df = column_one_hot(df, ['ProductVersion', 'Project_name', 'section',\n",
    "       'Project_category', 'BS', 'RU', 'ProjectYear'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df\n",
    "text = \"Zur Anschaltung des Antriebes in der Außenanlage müssen Signalkabel nach VDE 0816/2 oder Kabel mit vergleichbaren Eigenschaften verwendet werden. Die Verlegevorschriften des Kabels sind einzuhalten.\"\n",
    "df_training = df_training.loc[df_training['Text'] == text]\n",
    "df_training.reset_index(inplace=True, drop=True)\n",
    "\n",
    "test_col = 8\n",
    "test = drop_columns(df_training.iloc[[test_col]], ['Text', 'Status', 'Statement'])\n",
    "df_training = df_training.drop(test_col)\n",
    "\n",
    "trainX = drop_columns(df_training, ['Status', 'Text', 'Statement'])\n",
    "trainYStatus = drop_column(column_one_hot(df_training[['Text', 'Status']], ['Status']), \"Text\")\n",
    "trainYStatement = drop_column(column_one_hot(df_training[['Text', 'Statement']], ['Statement']), \"Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 8)                 1424      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,619\n",
      "Trainable params: 1,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "5/5 - 1s - loss: 1.1121 - categorical_accuracy: 0.3333 - val_loss: 1.1320 - val_categorical_accuracy: 0.1429 - 1s/epoch - 290ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 1.0783 - categorical_accuracy: 0.3333 - val_loss: 1.1325 - val_categorical_accuracy: 0.1429 - 72ms/epoch - 14ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 1.0581 - categorical_accuracy: 0.3333 - val_loss: 1.1283 - val_categorical_accuracy: 0.1429 - 77ms/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 1.0386 - categorical_accuracy: 0.4444 - val_loss: 1.1242 - val_categorical_accuracy: 0.1429 - 70ms/epoch - 14ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 1.0236 - categorical_accuracy: 0.4444 - val_loss: 1.1236 - val_categorical_accuracy: 0.4286 - 62ms/epoch - 12ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 1.0075 - categorical_accuracy: 0.4444 - val_loss: 1.1252 - val_categorical_accuracy: 0.4286 - 66ms/epoch - 13ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 0.9934 - categorical_accuracy: 0.5556 - val_loss: 1.1254 - val_categorical_accuracy: 0.4286 - 77ms/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 0.9778 - categorical_accuracy: 0.5556 - val_loss: 1.1253 - val_categorical_accuracy: 0.4286 - 73ms/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 0.9635 - categorical_accuracy: 0.5556 - val_loss: 1.1273 - val_categorical_accuracy: 0.4286 - 58ms/epoch - 12ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 0.9473 - categorical_accuracy: 0.5556 - val_loss: 1.1293 - val_categorical_accuracy: 0.4286 - 62ms/epoch - 12ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 0.9302 - categorical_accuracy: 0.6667 - val_loss: 1.1313 - val_categorical_accuracy: 0.4286 - 60ms/epoch - 12ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 0.9128 - categorical_accuracy: 0.6667 - val_loss: 1.1289 - val_categorical_accuracy: 0.4286 - 62ms/epoch - 12ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 0.8990 - categorical_accuracy: 0.6667 - val_loss: 1.1305 - val_categorical_accuracy: 0.4286 - 61ms/epoch - 12ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 0.8838 - categorical_accuracy: 0.5556 - val_loss: 1.1347 - val_categorical_accuracy: 0.4286 - 74ms/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 0.8697 - categorical_accuracy: 0.7778 - val_loss: 1.1351 - val_categorical_accuracy: 0.4286 - 60ms/epoch - 12ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 0.8546 - categorical_accuracy: 0.7778 - val_loss: 1.1410 - val_categorical_accuracy: 0.4286 - 52ms/epoch - 10ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 0.8414 - categorical_accuracy: 0.7778 - val_loss: 1.1477 - val_categorical_accuracy: 0.4286 - 67ms/epoch - 13ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.8271 - categorical_accuracy: 0.7778 - val_loss: 1.1475 - val_categorical_accuracy: 0.4286 - 55ms/epoch - 11ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 0.8124 - categorical_accuracy: 0.7778 - val_loss: 1.1553 - val_categorical_accuracy: 0.4286 - 66ms/epoch - 13ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.7981 - categorical_accuracy: 0.7778 - val_loss: 1.1610 - val_categorical_accuracy: 0.4286 - 87ms/epoch - 17ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.7850 - categorical_accuracy: 0.7778 - val_loss: 1.1680 - val_categorical_accuracy: 0.4286 - 77ms/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.7715 - categorical_accuracy: 0.7778 - val_loss: 1.1762 - val_categorical_accuracy: 0.4286 - 92ms/epoch - 18ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 0.7599 - categorical_accuracy: 0.7778 - val_loss: 1.1773 - val_categorical_accuracy: 0.4286 - 81ms/epoch - 16ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.7490 - categorical_accuracy: 0.7778 - val_loss: 1.1885 - val_categorical_accuracy: 0.4286 - 69ms/epoch - 14ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 0.7383 - categorical_accuracy: 0.7778 - val_loss: 1.1948 - val_categorical_accuracy: 0.4286 - 69ms/epoch - 14ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.7271 - categorical_accuracy: 0.7778 - val_loss: 1.1980 - val_categorical_accuracy: 0.4286 - 69ms/epoch - 14ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 0.7180 - categorical_accuracy: 0.6667 - val_loss: 1.2069 - val_categorical_accuracy: 0.4286 - 83ms/epoch - 17ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 0.7079 - categorical_accuracy: 0.7778 - val_loss: 1.2181 - val_categorical_accuracy: 0.4286 - 141ms/epoch - 28ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.6969 - categorical_accuracy: 0.7778 - val_loss: 1.2267 - val_categorical_accuracy: 0.4286 - 99ms/epoch - 20ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.6867 - categorical_accuracy: 0.7778 - val_loss: 1.2373 - val_categorical_accuracy: 0.4286 - 75ms/epoch - 15ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.6777 - categorical_accuracy: 0.6667 - val_loss: 1.2472 - val_categorical_accuracy: 0.4286 - 65ms/epoch - 13ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.6683 - categorical_accuracy: 0.7778 - val_loss: 1.2599 - val_categorical_accuracy: 0.1429 - 56ms/epoch - 11ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.6538 - categorical_accuracy: 0.7778 - val_loss: 1.2742 - val_categorical_accuracy: 0.1429 - 57ms/epoch - 11ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.6422 - categorical_accuracy: 0.7778 - val_loss: 1.2877 - val_categorical_accuracy: 0.1429 - 57ms/epoch - 11ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.6315 - categorical_accuracy: 0.7778 - val_loss: 1.2953 - val_categorical_accuracy: 0.1429 - 64ms/epoch - 13ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.6206 - categorical_accuracy: 0.7778 - val_loss: 1.3134 - val_categorical_accuracy: 0.1429 - 63ms/epoch - 13ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.6115 - categorical_accuracy: 0.7778 - val_loss: 1.3119 - val_categorical_accuracy: 0.1429 - 54ms/epoch - 11ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.6011 - categorical_accuracy: 0.7778 - val_loss: 1.3248 - val_categorical_accuracy: 0.1429 - 55ms/epoch - 11ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.5911 - categorical_accuracy: 0.7778 - val_loss: 1.3394 - val_categorical_accuracy: 0.1429 - 57ms/epoch - 11ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.5814 - categorical_accuracy: 0.7778 - val_loss: 1.3510 - val_categorical_accuracy: 0.1429 - 55ms/epoch - 11ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.5711 - categorical_accuracy: 0.7778 - val_loss: 1.3713 - val_categorical_accuracy: 0.1429 - 56ms/epoch - 11ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.5604 - categorical_accuracy: 0.7778 - val_loss: 1.3808 - val_categorical_accuracy: 0.1429 - 57ms/epoch - 11ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.5530 - categorical_accuracy: 0.7778 - val_loss: 1.3885 - val_categorical_accuracy: 0.1429 - 61ms/epoch - 12ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.5421 - categorical_accuracy: 0.7778 - val_loss: 1.4021 - val_categorical_accuracy: 0.1429 - 68ms/epoch - 14ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.5367 - categorical_accuracy: 0.7778 - val_loss: 1.4123 - val_categorical_accuracy: 0.1429 - 57ms/epoch - 11ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.5292 - categorical_accuracy: 0.7778 - val_loss: 1.4194 - val_categorical_accuracy: 0.1429 - 69ms/epoch - 14ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.5220 - categorical_accuracy: 0.7778 - val_loss: 1.4349 - val_categorical_accuracy: 0.1429 - 79ms/epoch - 16ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.5157 - categorical_accuracy: 0.7778 - val_loss: 1.4433 - val_categorical_accuracy: 0.1429 - 60ms/epoch - 12ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.5178 - categorical_accuracy: 0.7778 - val_loss: 1.4436 - val_categorical_accuracy: 0.1429 - 55ms/epoch - 11ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.5068 - categorical_accuracy: 0.7778 - val_loss: 1.4526 - val_categorical_accuracy: 0.1429 - 57ms/epoch - 11ms/step\n"
     ]
    }
   ],
   "source": [
    "modelStatus = Sequential()\n",
    "modelStatus.add(Dense(8, input_shape=(trainX.shape[1],), activation='relu'))\n",
    "modelStatus.add(Dense(16, activation='relu'))\n",
    "modelStatus.add(Dense(trainYStatus.shape[1], activation='softmax'))\n",
    "modelStatus.summary()\n",
    "modelStatus.compile(optimizer='rmsprop',\n",
    "              loss=CategoricalCrossentropy(),\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "historyStatus = modelStatus.fit(trainX, trainYStatus,\n",
    "                    batch_size=2,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    validation_split=0.4)\n",
    "\n",
    "#modelStatement = Sequential()\n",
    "#modelStatement.add(Dense(16, input_shape=(trainX.shape[1],), activation='relu'))\n",
    "#modelStatement.add(Dense(8, activation='relu'))\n",
    "#modelStatement.add(Dense(trainYStatement.shape[1], activation='softmax'))\n",
    "#modelStatement.summary()\n",
    "#modelStatement.compile(optimizer='adam',\n",
    "#              loss=CategoricalCrossentropy(),\n",
    "#              metrics=['accuracy'])\n",
    "#\n",
    "#historyStatement = modelStatement.fit(trainX, trainYStatement,\n",
    "#                    batch_size=2,\n",
    "#                    epochs=50,\n",
    "#                    verbose=2,\n",
    "#                    validation_split=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "closed 5.9%\n",
      "compliant 81.0%\n",
      "not applicable 13.0%\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "predictionStatus = modelStatus.predict(test)\n",
    "col = 0\n",
    "for i in predictionStatus:\n",
    "    for j in i:\n",
    "        print (trainYStatus.columns[col] + \" \" + '{:.1%}'.format(j))\n",
    "        col += 1\n",
    "\n",
    "print (\"-----------------------------------------------------\")\n",
    "\n",
    "#predictionStatement = modelStatement.predict(test)\n",
    "#index_max = np.argmax(predictionStatement)\n",
    "#print (trainYStatement.columns[index_max] + \" \" + '{:.1%}'.format(predictionStatement[0][index_max]))\n",
    "#col = 0\n",
    "#for i in predictionStatement:\n",
    "#    for j in i:\n",
    "#        print (trainYStatement.columns[col] + \" \" + '{:.1%}'.format(j))\n",
    "#        col += 1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional\n",
    "inputs = Input(shape=trainX.shape[1])\n",
    "\n",
    "hidden_layer = Dense(16, activation='relu')(inputs)\n",
    "\n",
    "output1 = Dense(trainYStatus.shape[1], activation='softmax', name='status')(hidden_layer)\n",
    "\n",
    "output2 = Dense(trainYStatement.shape[1], activation='softmax', name='statement')(hidden_layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[output1, output2])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'status': CategoricalCrossentropy(), 'statement': CategoricalCrossentropy()},\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(trainX, {'status': trainYStatus, 'statement': trainYStatement},\n",
    "                    batch_size=2,\n",
    "                    epochs=50,\n",
    "                    verbose=2,\n",
    "                    validation_split=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional!\n",
    "# Vorhersage machen\n",
    "output_status, output_statement = model.predict(test)\n",
    "\n",
    "# Ausgabe 1 vorhersagen\n",
    "status_prediction = np.argmax(output_status)\n",
    "\n",
    "# Ausgabe 2 vorhersagen\n",
    "statement_prediction = np.argmax(output_statement)\n",
    "\n",
    "for val in output_status:\n",
    "    print (str(val))\n",
    "\n",
    "#print(\"Status Probabilities:\", output_status)\n",
    "#print(\"Statement Prediction:\", statement_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nur noch Infos --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = df['Status'].unique()\n",
    "hauefigkeit = []\n",
    "for x in status:\n",
    "    hauefigkeit.append(len(df[df['Status'] == x]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(hauefigkeit, labels=status, autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HQ' 'AT' 'CN' 'DE' 'UK']\n"
     ]
    }
   ],
   "source": [
    "print(df['RU'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i], y[i], ha = 'center')\n",
    "\n",
    "text = df['Text'].value_counts()\n",
    "eins = 0\n",
    "zwei = 0\n",
    "drei = 0\n",
    "vier = 0\n",
    "for anzahl in text:\n",
    "    if anzahl  < 5:                         # anzahl 0:4\n",
    "        eins += 1\n",
    "    if ((anzahl  >= 5) & (anzahl <= 9)):           # anzahl 5:9\n",
    "        zwei += 1                           \n",
    "    if ((anzahl  >= 10) & (anzahl <= 14)):           # anzahl 10:14\n",
    "        drei += 1\n",
    "    if anzahl  >= 15:                       # anzahl ab 15\n",
    "        vier += 1\n",
    "y = [eins, zwei, drei, vier]\n",
    "x = ('0-4', '5-9', '10-14', 'ab 15')\n",
    "\n",
    "\n",
    "plt.bar(x, y, align='center')\n",
    "plt.xticks(x)\n",
    "plt.title('Anzahl Anwendungsregeln nach Häufigkeit der Bewertung')\n",
    "addlabels(x, y)\n",
    "plt.show()\n",
    "\n",
    "print (\"Anzahl Anwendungsregeln, welche nur einmal bewertet wurden: \" + str(eins))\n",
    "print (\"Anteil am Datensatz: \" + str(round(round(eins/df.shape[0], 4) * 100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Text'].value_counts()\n",
    "text.head()\n",
    "test = df.loc[df['Text'] == \"Zur Anschaltung des Antriebes in der Außenanlage müssen Signalkabel nach VDE 0816/2 oder Kabel mit vergleichbaren Eigenschaften verwendet werden. Die Verlegevorschriften des Kabels sind einzuhalten.\"]\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "test.head(17)\n",
    "#df['Text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historyStatus.history['loss'], label = 'Training loss')\n",
    "plt.plot(historyStatus.history['val_loss'], label = 'Validation loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
