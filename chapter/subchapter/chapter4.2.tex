\section{Sammeln zusätzlicher Daten}
\label{chap:DatenSammeln}
Wie in Kapitel \ref*{chap:DataPraxisprojekt} bereits erwähnt, besteht die Möglichkeit über eine Access-Datenbank noch weitere Daten über die Projekte zu sammeln.
Aus den Inhalten dieser Access-Datenbank wird jeden Tag eine XML-Datei erstellt, welche ebenfalls in das Python-Skript mit der Pandas-Bibliothek importiert werden kann.
In dieser XML-Datei kann nach den Projekten aus dem Datensatz gesucht werden und der Datensatz kann mit den Daten aus der XML-Datei erweitert werden.
Zunächst wird eine Liste erstellt, die alle eindeutigen Projekte aus dem Datensatz enthält. Diese Liste wird verwendet, um eine Schleife durchzuführen, 
in der jeder Projektname nacheinander durchlaufen wird. In der Schleife wird für jedes Projekt der Eintrag aus der Access-Datenbank gesucht.
Dabei muss der Eintrag drei Bedingungen erfüllen:
\\ \\
\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
    \item \glqq Type\grqq{} muss den Wert \glqq Real\grqq{} besitzen
        \begin{itemize}[itemindent=0cm]
            \item Projekte mit dem \glqq Type\grqq{} \glqq Real\grqq{} befinden sich in der Projektabwicklungsphase
        \end{itemize}
    \item \glqq Location\grqq{} muss den Wert \glqq BWG\grqq{} besitzen
        \begin{itemize}[itemindent=0cm]
            \item \glqq BWG\grqq{} steht hierbei für die \ac{RM} Datenbank Braunschweig
        \end{itemize}
    \item \glqq Offset\grqq{} muss den Wert \glqq path\grqq{} besitzen
        \begin{itemize}[itemindent=0cm]
            \item stellt sicher, dass der Eintrag zum richtigen Projekt gehört
            \item In einem Land existieren mehrere Projekte mit demselben Namen, im Datensatz ist damit jedoch ein bestimmtes Projekt gemeint, die Namen mussten hier anonymisiert werden
        \end{itemize}
\end{enumerate}
Das Prüfen dieser Bedingungen ist eingebettet in einen try-except-Block. Der try-except-Block sorgt dafür, dass eine Fehlermeldung auftritt, falls in der Access-Datenbank ein Eintrag nicht gefunden wird.
Wenn hingegen ein Eintrag gefunden wird, wird die erste gefundene Zeile in einer Variable \glqq result\grqq{} gespeichert. Quellcode \ref*{lst:ImportAccess} zeigt den Code, um diese Schritte durchzuführen.
\begin{lstlisting}[language = python, caption={Importieren der Access-Datenbank},captionpos=b, label = lst:ImportAccess, floatplacement=H]
    paths = df['Path'].unique()
    accDB = pd.read_xml(".../Input_BWG_Combined_Access.xml")
    for path in paths:
        try:
            if(path == "..."):
                result = accDB.loc[(accDB['Type'] == "Real") 
                & (accDB['Location'] == "BWG") 
                & (accDB['Offset'] == "...")].iloc[0]
            else:
                result = accDB.loc[(accDB['Type'] == "Real") 
                & (accDB['Location'] == "BWG") 
                & ((accDB['Offset'] == str(path)) 
                | (accDB['Offset'] == (str(path) + "/")))].iloc[0]           
        except:
            print(str(path) + " has no entry in the AccessDB!")
\end{lstlisting}
\glqq result\grqq{} enthält nun alle Attribute über das Projekt, die in der Access-Datenbank vorhanden sind. Diese relevanten Informationen müssen nun dem ursprünglichen 
Datensatz hinzugefügt werden. Noch in derselben Schleife wie im Quellcode \ref*{lst:ImportAccess}, werden dem Datensatz neue Spalte hinzugefügt und mit den Werten aus der 
Access-Datenbank gefüllt. Quellcode \ref*{lst:addData} zeigt in Zeile drei ein Beispiel dafür. Durch diese Zeile werden alle Zeilen aus dem Datensatz aktualisiert, 
die in der \glqq Path\grqq{}-Spalte den aktuellen \glqq path\grqq{}-Wert haben. Der Wert der neuen Spalte wird dabei aus der entsprechenden Spalte von \glqq result\grqq{} übernommen.
Dieser Schritt wird ebenfalls für die anderen Spalten aus der Access-Datenbank ausgeführt. Zum Schluss wird noch die Versionsbezeichnung angepasst. 
Es kann der Fall auftreten, dass zwei verschiedene Produkte dieselbe Versionsbezeichnung besitzen, zum Beispiel \glqq 2\grqq{} oder \glqq 01.5\grqq{}. Um das zu verhindern,
wird vor die Versionsbezeichnung noch der Name des Produkts gestellt, damit sich Versionsbezeichnungen von verschiedenen Produkten nicht mehr gleichen können.
\begin{lstlisting}[language = python, caption={Erweiterung des Datensatzes},captionpos=b, label = lst:addData, floatplacement=H]
    for path in paths:
        #...
        df.loc[df['Path'] == str(path), 'Project_category']
        = result['Project_category']
        #...
        df['ProductVersion'] 
        = df["Product"].str.cat(df["Version"], sep = "-")
\end{lstlisting}
Das Ergebnis dieser Schritte ist ein Datensatz in Form eines Dataframes mit 14.572 Zeilen und 11 verschiedenen Spalten. Diese zusätzlichen Daten wurden gesammelt, um Ähnlichkeiten von Projekten 
nutzen zu können. Je stärker sich Projekte ähneln, desto eher werden die Anwendungsregeln der Projekte ähnlich bewertet. Die Spalten dieses Dataframes sind die folgenden und dienen, bis auf die 
Spalte \glqq Text\grqq{}, als Datensatz für das Anlernen des \ac{KI}-Modells:
\begin{description}[style=multiline,leftmargin=4cm,font=\bfseries, nolistsep]
    \item[Text] Text der Anwendungsregel
    \item[Product] Name des Produkts
    \item[ProductVersion] Version des Produkts
    \item[Project\_name] Name des Projekts, das die Anwendungsregel bearbeiten musste
    \item[section] Sektion, die das Projekt durchführt, zum Beispiel ML für MainLine oder MT für MassTransit
    \item[Project\_category] Kategorie des Projekts, gibt Aufschluss über die Größe eines Projekts
    \item[BS] Business Segment, in dem das Projekt angesiedelt ist
    \item[RU] Region, in der das Projekt durchgeführt wird
    \item[ProjectYear] Jahr, in dem das Projekt gestartet wurde
    \item[Status] Status der Anwendungsregel
    \item[Statement] Begründung zum Status
\end{description} 

Eine weitere Möglichkeit zur Erzeugung weiterer Daten aus dem bestehenden Datensatz wäre die Data Augmentation. Bei diesem Verfahren werden die bestehenden Daten 
leicht abgeändert, damit weitere Daten synthetisch erstellt werden können, was zu einem größeren Datensatz führt. Diese Praxis wird häufig im Bereich der Computer Vision,
also dem \glqq maschinellen Sehen\grqq{}, genutzt. Computer Vision beschäftigt sich mit der Verarbeitung von Bildern und Videos, weshalb dabei die Datensätze 
aus Bildern und Videos bestehen. Auf den Daten können verschiedene Transformationen ausgeführt werden, zum Beispiel kann ein Bild gespiegelt oder gedreht werden, um aus 
einem Bild mehrere zu erzeugen \cite[vgl. S.184f.]{DL_PY}. In dem in dieser Arbeit beschriebenem Anwendungsfall bietet sich Data Augmentation jedoch nicht an. Da der Datensatz überwiegend
aus kategorischen Attributen besteht, müssten einige Kategorien andere Werte bekommen, um aus den vorhandenen Daten weitere zu erzeugen. Dies könnte zum Beispiel dazu führen,
dass eine Zeile im Datensatz, die beispielsweise zu einem Projekt, das eigentlich der Kategorie \glqq A\grqq{} zugehört, unterschiedlichen Kategorien zugeordnet wird, 
was aber zu einem Widerspruch im Datensatz führen könnte. Zudem könnten durch das Manipulieren des Datensatzes zufällige Strukturen und Zusammenhänge erzeugt werden,
die in der Realität nicht existieren. Da der Datensatz relativ klein ist, könnte ein \ac{NN} diese falschen Strukturen erkennen und diese lernen. Dies wäre kritisch zu betrachten,
da Anwendungsregeln sicherheitsrelevant sein können. Deshalb wurde in dieser Arbeit davon abgesehen, dieses Verfahren zu verwenden.

\section{Codierung der Attribute}
Im nächsten Schritt muss der Datensatz in eine Form gebracht werden, die für das Anlernen eines \ac{KI}-Modells geeignet ist. Die ausgewählten Attribute stellen alle Kategorien in 
Textform oder als Jahreszahl dar. Beide Darstellungsformen sind ungeeignet, um als Trainingsdatensatz zu dienen, da ein \ac{NN} mit numerischen Werten arbeitet. 
Eine Möglichkeit zur Codierung von kategoriellen Attributen ist die One-Hot-Codierung. Dabei wird jeder Ausprägung eines Attributs eine eigene neue Spalte zugeordnet 
und für jede Zeile hat nur eine Spalte den Wert 1, alle anderen Spalten nehmen den Wert 0 an. Die beiden nachfolgenden Tabellen zeigen anhand eines Beispiels die 
One-Hot-Codierung des Attributs \glqq ProjectYear\grqq{}.
\\  
\\
\begin{minipage}[c]{0.5\textwidth}
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Text} & \textbf{ProjectYear}\\ \hline
        Text1&2019\\
        Text2&2021\\
        Text3&2022\\
        \hline
    \end{tabular}
    \captionof{table}{Ursprügliche Tabelle}
\end{minipage}
\begin{minipage}[c]{0.5\textwidth}
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Text} & \textbf{2019} & \textbf{2021} & \textbf{2022}\\ \hline
        Text1 & 1 & 0 & 0\\
        Text2 & 0 & 1 & 0\\
        Text3 & 0 & 0 & 1\\
        \hline
    \end{tabular}
    \captionof{table}{Nach One-Hot-Codierung}
\end{minipage}
\\
\\
Um auf den Spalten des Dataframes in Python die One-Hot-Codierung auszuführen, wurde eine neue Funktion geschrieben, die dem Quellcode \ref{lst:OneHot} entnommen werden kann.
Diese Funktion erhält als Parameter einen Dataframe sowie eine Liste an Spalten, auf denen die One-Hot-Codierung durchgeführt werden soll. In einer Schleife iteriert die Funktion 
über jede Spalte, die in der Liste übergeben wurde und prüft anschließend, ob diese Spalte im Dataframe vorhanden ist. Wenn dies der Fall ist, wird mithilfe der 
get\_dummies()-Methode aus der Pandas-Bibliothek die One-Hot-Codierung durchgeführt. Anschließend wird die ursprüngliche Spalte aus dem Dataframe entfernt und dafür werden
die neuen codierten Spalten dem Dataframe hinzugefügt. Dafür werden die drop()- und concat()-Methode der Pandas-Bibliothek genutzt, die es ermöglichen Spalten und Zeilen
hinzuzufügen oder zu entfernen \cite{PandasDoc}.

\begin{lstlisting}[language = python, caption={Funktion zur One-Hot-Codierung},captionpos=b, label = lst:OneHot, floatplacement=H]
    def col_one_hot (df, columns): 
        for column in columns:
            if column in df:
                one_hot = pd.get_dummies(df[column])
                df = df.drop(column,axis = 1)
                df = pd.concat([df, one_hot], axis=1)
        return df
\end{lstlisting}

Die Attribute \glqq Product\grqq{} und \glqq ProductVersion\grqq{} stellen hier jedoch einen Sonderfall dar. Aufgrund der One-Hot-Codierung kann in jeder Zeile nur eine Ausprägung
eines Attributs den Wert 1 annehmen, jedoch benutzen Projekte mehrere Produkte und verschiedene Produktversionen. Deshalb muss der Datensatz für diese beiden Attribute nochmal 
überarbeitet werden. Zunächst wird über alle Projekte und Produkte iteriert. Für jedes Produkt wird nun geprüft, ob es in einem Projekt vorhanden ist. Wenn dies der Fall ist,
wird der Wert für dieses Produkt in jeder Zeile des Projekts auf eins gesetzt. Äquivalent wird mit dem Attribut \glqq ProductVersion\grqq{} verfahren. 

\begin{lstlisting}[language = python, caption={Anpassung der Spalte \glqq Product\grqq},captionpos=b, label = lst:ProductOneHot, floatplacement=H]
    df = col_one_hot(df, ['Product'])
    for project in projects:
        for product in products:
            curProject = df.loc[df['Project_name'] == project]
            df.loc[df['Project_name'] == project, product] = 1 if 
                (curProject[product].sum()) >= 1 else 0
    df = col_one_hot(df, ['ProductVersion', 'Project_name', 
    'section', 'Project_category', 'BS', 'RU', 'ProjectYear'])
    ---------------------------------------
    Output:
    (14572, 180)
\end{lstlisting}

Nachdem die beiden Attribute korrekt codiert wurden, können die restlichen Attribute ebenfalls codiert werden, wie im Quellcode \ref*{lst:ProductOneHot} gezeigt wird.
Aus den ursprünglichen 11 Spalten wurden nach der Codierung der Attribute 180 verschiedene Spalten.

Eine Variante der One-Hot-Codierung ist der One-Hot-Hashing-Trick, der sich anbietet, wenn die Anzahl an Attributen in einem Datensatz zu hoch ist. Anstatt jede Ausprägung
eines Attributs als neue Spalte zu definieren, kann auch eine Hashfunktion genutzt werden, um die Ausprägungen abzubilden. François Chollet nutzt diese Variante
der One-Hot-Codierung bei der Codierung von Wörtern und Zeichen. In seinem Beispiel codiert er die 1000 am häufigsten vorkommenden Wörter \cite[vgl. S.236]{DL_PY}. Da der Datensatz in dieser Arbeit aber 
nicht über so viele verschiedene Spalten verfügt, wurde diese Variante der One-Hot-Codierung hier nicht genutzt.

Neben den beiden Varianten existieren noch weitere Möglichkeiten zur Codierung von kategorischen Attributen. Ein weiteres Beispiel wäre das Label-Encoding. Dabei wird jeder Ausprägung eines Attributs
ein eindeutiger Integer-Wert zugeordnet. Die nachfolgenden Tabellen zeigen ein Beispiel für das Label-Encoding eines Attributs. Dem Produkt \glqq SICAS ECC\grqq{} wird dabei der Wert 0 zugeordnet,
dem Produkt \glqq LZB700m\grqq{} 1 und so weiter. 
\\
\\
\begin{minipage}[c]{0.5\textwidth}
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Text} & \textbf{Product}\\ \hline
        Text1 & SICAS ECC\\
        Text2 & LZB700M\\
        Text3 & SIMIS IS\\
        \hline
    \end{tabular}
    \captionof{table}{Ursprügliche Tabelle}
\end{minipage}
\begin{minipage}[c]{0.5\textwidth}
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Text} & \textbf{Product} \\ \hline
        Text1 & 0\\
        Text2 & 1\\
        Text3 & 2\\
        \hline
    \end{tabular}
    \captionof{table}{Nach Label-Encoding}
\end{minipage}
\\
\\
Im Vergleich zur One-Hot-Codierung besteht hier der Vorteil, dass nicht für jede Ausprägung eine neue Spalte hinzugefügt wird und 
die Dimension des Datensatzes somit nicht größer wird. Der entscheidende Nachteil des Label-Encodings tritt jedoch auf, wenn die Ausprägungen nicht in einer Beziehung zueinander stehen.
Durch das Zuweisen von aufsteigenden Integer-Werten erweckt diese Art der Codierung den Eindruck, dass die Beziehung \glqq SICAS ECC\grqq{} < \glqq LZB700m\grqq{} < \glqq SIMIS IS\grqq{} besteht,
obwohl das gar nicht der Fall ist. Deshalb wurde in dieser Arbeit das Label-Encoding verworfen und stattdessen die One-Hot-Codierung genutzt.
