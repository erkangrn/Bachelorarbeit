\section{Verbesserungen des ersten Modells}
\label{chap:VerbesserungenNN}

In Kapitel \ref*{chap:DefineNN} wurde gezeigt, wie ein Modell für die Vorhersage für den Statuswert aussehen kann. Diese Schritte müssten ebenfalls für das dazugehörige Statement
durchlaufen werden. Das Ergebnis wären zwei unabhängige Modelle, die beide jeweils einzeln und nacheinander trainiert werden müssen. Diese Aufteilung ist nötig gewesen,
da die \glqq Sequential\grqq{}-Klasse es nicht erlaubt mehrere Ausgabeschichten zu definieren und da die \glqq softmax\grqq{}-Funktion allen Ausgabeneuronen 
einen Wert zuordnet, die addiert eins ergeben. Um dieses Problem zu umgehen, kann statt der \glqq Sequential\grqq{}-Klasse von Keras, 
ein \ac{API}, nämlich die funktionale Keras-\ac{API} verwendet werden. 
Dadurch wird es ermöglicht Modelle zu definieren, die mehr als eine Eingabe- oder Ausgabeschicht haben oder Verzweigungen zwischen den Layern besitzen \cite[vgl. S.299f.]{DL_PY}. 
Abbildung \ref*{fig:FunktionaleAPI} zeigt den Aufbau eines \ac{NN} mit zwei Ausgabeschichten. Genau so ein Modell wird im nächsten Schritt mit der funktionalen Keras-\ac{API} erstellt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{abbildungen/NN_funktionaleAPI.pdf}
    \caption{Modell mit zwei Ausgabeschichten}
    \label{fig:FunktionaleAPI}
\end{figure}

Grundsätzlich ist es möglich jedes Modell, welches mit der \glqq Sequential\grqq{}-Klasse erstellt wurde, in ein Modell mit der funktionalen Keras-\ac{API} zu übersetzen. 
Deshalb wird als Erstes das bestehende und in Kapitel \ref*{chap:DefineNN} beschriebene Modell übersetzt und im Anschluss daran wird dem Modell eine zweite Ausgabeschicht
hinzugefügt.
Mit der funktionalen \ac{API} werden Tensoren direkt bearbeitet und können den Schichten, wie bei einer Funktion, übergeben und entgegengenommen werden. Ein Tensor ist eine
Datenstruktur, welche als n-dimensionales-Array beschrieben werden kann. Skalare sind Tensoren der Stufe 0, Vektoren sind Tensoren der Stufe 1, Matrizen sind Tensoren
der Stufe 2 und so weiter \cite[vgl. S.128]{AI_Huawei}. Ziel dabei ist es 
aus einem Eingabetensor einen Ausgabetensor zu erzeugen. Dafür ruft die Bibliothek alle Schichten ab, die an dieser Transformation beteiligt sind, und fasst diese Struktur
dann als Modell zusammen. Der Ausgabetensor entsteht also durch aufeinanderfolgende Transformationen des Eingabetensors \cite[vgl. S.305]{DL_PY}. 
Quellcode \ref*{lst:SeqToFunc} zeigt die Definition des Modells aus Kapitel \ref*{chap:DefineNN} mit der funktionalen \ac{API} und kann mit Quellcode \ref*{lst:ModellSeq}
verglichen werden. 

\begin{lstlisting}[language = python, caption={Modell mit funktionaler \acs{API} darstellen},captionpos=b, label = lst:SeqToFunc, floatplacement=H]
    input = Input(shape=(trainX.shape[1],))
    x = Dense(8, activation='relu')(input)
    x = Dense(16, activation='relu')(x)
    output = Dense(trainYStatus.shape[1], activation='softmax')(x)
    model = Model(input, output)
    model.summary()
    ---------------------------------------
    Output:
    ______________________________________________________________
    Layer (type)                Output Shape              Param #   
    ==============================================================
    input_9 (InputLayer)        [(None, 177)]             0         
                                                                    
    dense_36 (Dense)            (None, 8)                 1424      
                                                                    
    dense_37 (Dense)            (None, 16)                144       
                                                                    
    dense_38 (Dense)            (None, 3)                 51        
                                                                    
    ==============================================================
    Total params: 1,619
    Trainable params: 1,619
    Non-trainable params: 0
    ______________________________________________________________

\end{lstlisting}

Anders als bei der Erstellung des Modells mit der \glqq Sequential\grqq{}-Klasse, wird hier die Dimension der Eingabedaten nicht in der ersten Schicht als Parameter übergeben,
sondern wird noch vorher festgelegt. Wie in der Zusammenfassung des Modells zu sehen ist, stellt \glqq Input\grqq{} jedoch keine wirkliche erste Schicht dar,
da sie keine Parameter besitzt. Bis auf diesen Unterschied ist die Zusammenfassung beider Modelle gleich. Der Prozess des Trainierens und die Auswahl der Verlustfunktion
sowie des Optimierers sind ebenfalls identisch. Deshalb sind beide Modelle in der Anwendung äquivalent. Nun muss noch eine weitere zusätzliche Ausgabeschicht hinzugefügt werden,
welche das Statement zur Bewertung der Anwendungsregel prognostizieren soll. Dafür werden Zeile vier und fünf des Quellcodes \ref*{lst:SeqToFunc} überarbeitet, was 
in Quellcode \ref*{lst:Outputs} gezeigt wird.

\begin{lstlisting}[language = python, caption={Zweite Ausgabeschicht hinzufügen},captionpos=b, label = lst:Outputs, floatplacement=H]
    output1 = Dense(trainYStatus.shape[1], activation='softmax', name='status')(x)
    output2 = Dense(trainYStatement.shape[1], activation='softmax', name='statement')(x)
    model = Model(inputs=input, outputs=[output1, output2])
\end{lstlisting}

Beide Ausgabeschichten erhalten als Parameter die Anzahl an möglichen Ausprägungen ihres Zielattributs sowie eine Aktivierungsfunktion. An dieser Stelle wäre es möglich
auch verschiedene Aktivierungsfunktionen auszuwählen, sollte beispielsweise ein Zielattribut das Ergebnis einer Regression sein, könnte hier auch 
\glqq mse\grqq{} gewählt werden. Zudem erhalten die beiden Layer noch einen eindeutigen Namen. Beim Aufruf der compile()-Methode besteht dadurch die Möglichkeit 
den beiden Schichten unterschiedliche Verlustfunktionen zuzuweisen \cite[vgl. S.308f.]{DL_PY}. Da beide Layer hier jedoch eine Single-Label-Mehrfachklassifizierung lösen sollen,
wird das nicht benötigt. 

Das Übersetzen der beiden Modelle mit der \glqq Sequential\grqq{}-Klasse in ein Modell mit der funktionalen \ac{API} hat den Vorteil, dass nun nur noch ein Modell 
erstellt und trainiert werden muss, was die Laufzeit des Modells halbiert und zudem Zeilen an Code spart.

\subsection{Wahl des Optimierers}

Wie in Kapitel \ref*{chap:DefineNN} beschrieben, ist es schwierig vorher zu bestimmen, welcher Optimierer die beste Performance liefert. Die Herangehensweise
um den idealen Optimierer zu finden ist daher Trial-and-Error. Dafür wird mit einer k-cross-Validierung der mittlere Wert der Verlustfunktion für den Statuswert
über mehrere Epochen und mit verschiedenen Optimierern visualisiert und anschließend geprüft, welcher Optimierer den niedrigsten Wert liefert. Es werden die Optimierer 
\glqq Adam\grqq{}, \glqq RMSprop\grqq{} und \glqq SGD\grqq{} ausprobiert.
Hier wird nur der Statuswert betrachtet, da das Statement bei den meisten Anwendungsregeln einzigartig ist und somit selten eine genaue Übereinstimmung vorhanden ist.
Deshalb ist beim Statement die Genauigkeit in der Regel null und darum ist der Wert der Verlustfunktion für das Statement nicht aussagekräftig.

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\textwidth]{abbildungen/Optimierer/LossOptimierer.png}
    \caption{Vergleich verschiedener Optimierer}
    \label{fig:LossOptimierer}
\end{figure}

Das Diagramm in der Abbildung \ref*{fig:LossOptimierer} zeigt den Verlauf des mittleren Werts der Verlustfunktion über mehrere Epochen. Dort ist zu erkennen, dass 
der Adam-Optimierer insgesamt den niedrigsten Wert erreicht, weshalb dieser im Folgenden genutzt wird. Jedoch
unterscheiden sich die Werte mit den verschiedenen Optimierern bis zur ca. Epoche 50 nicht stark, weshalb davon auszugehen ist, dass die Wahl des Optimierers in diesem spezifischen
Anwendungsfall keine allzu große Rolle spielt.

Neben der Auswahl des Optimierers kann ebenfalls die Lernrate eine Rolle spielen. Die Lernrate ist ein Parameter, der den Optimierer beeinflusst, weshalb verschiedene Lernraten ausprobiert werden
sollten. Standardmäßig beträgt die Lernrate des Adam-Optimierers 0,001 \cite{KerasDoc}. Als weitere Lernraten werden 0,01 und 0,0001 gewählt, um zu prüfen, wie 
sich der Wert der Verlustfunktion ändert, wenn eine größere bzw. kleinere Lernrate gewählt wird.
Die Lernrate des Optimierers kann bei Aufruf der compile()-Methode festgelegt werden, wie der Quellcode \ref*{lst:Learnrate} zeigt.

\begin{lstlisting}[language = python, caption={Wahl der Lernrate},captionpos=b, label = lst:Learnrate, floatplacement=H]
    model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),
        loss   ={'status': CategoricalCrossentropy(), 
                 'statement': CategoricalCrossentropy()},
        metrics=['categorical_accuracy'])
\end{lstlisting}

Abbildung \ref*{fig:LossLR} zeigt den Verlauf der Verlustfunktion mit den drei verschiedenen Lernraten. Deutlich zu erkennen ist, dass ein Vergrößern der Lernrate zu 
einem wesentlich schlechteren Ergebnis führt. Die standardmäßige sowie die kleinere Lernrate ähneln sich in ihrem Verlauf, wobei die standardmäßige Lernrate
ein tieferes Minimum erreicht, weshalb der Wert der Lernrate in diesem Fall nicht verändert werden sollte.

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\textwidth]{abbildungen/Optimierer/LossLR.png}
    \caption{Vergleich verschiedener Lernraten}
    \label{fig:LossLR}
\end{figure}

\subsection{Anpassen der Modellarchitektur}
Nachdem mehrere Optimierer ausprobiert und sich für einen entschieden wurde, sollte im nächsten Schritt noch geprüft werden, ob durch eine Anpassung der Modellarchitektur
gegebenenfalls ein besseres Ergebnis erzielt werden kann. Ähnlich wie bei der Wahl des Optimierers im vorherigen Schritt, wird dies wieder durch Ausprobieren und 
anschließendes Visualisieren entschieden. Dabei wird die Anzahl an Schichten sowie die Anzahl an Neuronen in einer Schicht angepasst.
Zudem wird geprüft, ob mittels einer Dropout-Regularisierung ein besseres Ergebnis erzielt werden kann. 
Folgende Modellarchitekturen werden dargestellt:
\begin{description}[style=multiline,leftmargin=3cm,font=\bfseries, nolistsep]
    \item[M1] Modell mit zwei versteckten Schichten (32, 16 Neuronen)
    \item[M2] breiteres und tieferes Modell mit vier Schichten (256, 128, 64, 32 Neuronen) mit Dropout-Regularisierung
    \item[M3] breiteres und tieferes Modell mit vier Schichten (256, 128, 64, 32 Neuronen) ohne Dropout-Regularisierung
    \item[M4] Modell mit einer versteckten Schicht mit 16 Neuronen
    \item[M5] Modell mit einer versteckten Schicht mit 512 Neuronen
\end{description}
Ein Beispiel für eine Dropout-Regularisierung zeigt der Quellcode \ref*{lst:Dropout}. Die Dropout-Klasse erwartet als Parameter einen Wert zwischen null und eins. 
Dieser Wert stellt den Anteil an Neuronen dar, dessen Ausgabe während des Trainings auf null gesetzt wird.
\begin{lstlisting}[language = python, caption={Dropout-Regularisierung mit Keras},captionpos=b, label = lst:Dropout, floatplacement=H]
    x = Dense(256, activation='relu')(inputs)
    x = Dropout(0.2)(x)
    x = Dense(128, activation='relu')(x)
\end{lstlisting}
Der Verlauf des mittleren Wertes der Verlustfunktion wird in Abbildung \ref*{fig:LossModelle} für alle fünf Modelle dargestellt. Zu erkennen ist, dass die beiden Modelle mit 
der geringsten Anzahl an Neuronen (M1 und M4) die besten Ergebnisse erzielen, während die beiden Modelle mit der höchsten Komplexität (M2 und M3) die schlechtesten Ergebnisse
erzielen. Der Grund dafür ist vermutlich, dass die komplexeren Modelle zu komplex sind um das Problem zu lösen. Zudem wird der kleine Datensatz ebenfalls dafür sorgen,
dass simplerer Modelle in diesem Anwendungsfall bessere Leistungen erzielen. Auch die Dropout-Regularisierung bringt in diesem Anwendungsfall kein besseres Ergebnis. Das Minimum
des Modells M1 lässt sich mit der argmin()-Methode der Numpy-Bibliothek bestimmen. Bei Epoche 23 hat M1 sein globales Minimum. Deshalb sollte dieses Modell weiterhin genutzt werden
und beim Trainieren des Modells sollte als Anzahl an Epochen ein Wert um 23 gewählt werden, um ein bestmögliches Ergebnis in diesem Anwendungsfall zu erreichen.

\begin{figure}[H]
    \centering
    \includegraphics[width=.75\textwidth]{abbildungen/LossModelle.png}
    \caption{Vergleich verschiedener Modellarchitekturen}
    \label{fig:LossModelle}
\end{figure}